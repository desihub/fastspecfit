#!/usr/bin/env python

"""Validate the files generated by a given production.

validate-production --specprod fuji --mp 128 --statistics --validate
time fitsverify -q /global/cfs/cdirs/desi/spectro/fastspecfit/fuji/healpix/*/*/*/*/*.fits* > /global/cfs/cdirs/desi/spectro/fastspecfit/fuji/v2.0/logs/fitsverify-fuji.log &

validate-production --specprod guadalupe --mp 128 --statistics --validate
time fitsverify -q /global/cfs/cdirs/desi/spectro/fastspecfit/guadalupe/healpix/*/*/*/*/*.fits* > /global/cfs/cdirs/desi/spectro/fastspecfit/guadalupe/v2.0/logs/fitsverify-guadalupe.log &

validate-production --specprod iron --mp 128 --statistics --validate
time fitsverify -q /global/cfs/cdirs/desi/spectro/fastspecfit/iron/healpix/*/*/*/*/*.fits* > /global/cfs/cdirs/desi/spectro/fastspecfit/iron/v1.0/logs/fitsverify-iron.log &


"""
import os, argparse, pdb
from glob import glob
import numpy as np
import fitsio
import multiprocessing
from astropy.table import Table

from fastspecfit.io import DESI_ROOT_NERSC, ZWarningMask
desi_root = os.environ.get('DESI_ROOT', DESI_ROOT_NERSC)

from desiutil.log import get_logger, DEBUG
log = get_logger()

def _check_one_catalog(args):
    """Multiprocessing wrapper."""
    return check_one_catalog(*args) 

def check_one_catalog(zcatfile, specprod, version):

    from desitarget import geomask
    
    fastfile = zcatfile.replace('redux/{}/zcatalog/zpix-'.format(specprod), 'fastspecfit/{0}/{1}/catalogs/fastspec-{0}-'.format(specprod, version))
    
    log.info(f'Reading {zcatfile}')
    zcat = Table(fitsio.read(zcatfile, ext='ZCATALOG', columns=['TARGETID', 'Z', 'ZWARN', 'OBJTYPE']))

    log.info(f'Reading {fastfile}')
    fast = Table(fitsio.read(fastfile, ext='METADATA', columns=['TARGETID', 'Z', 'Z_RR', 'ZWARN']))

    indx_zcat, indx_fast = geomask.match(zcat['TARGETID'], fast['TARGETID'])
    zcat = zcat[indx_zcat]
    fast = fast[indx_fast]
    assert(len(zcat) == len(fast))
    assert(np.all(zcat['TARGETID'] == fast['TARGETID']))

    # zcat['Z'] and fast['Z_RR'] should always match but where zcat['Z'] and
    # fast['Z'] differ should be the QSOs with updated redshifts.
    assert(np.all(zcat['Z'] == fast['Z_RR']))

    zdiff = zcat['Z'] != fast['Z']
    if np.sum(zdiff) > 0:
        log.info('Found {:,d}/{:,d} ({:.4f}%) updated QSO redshifts in catalog {}'.format(
            np.sum(zdiff), len(fast), np.sum(zdiff)/len(fast), fastfile))

    outfile = os.path.basename(fastfile)
    outfile = outfile.replace('fastspec-', '{fastspec}-')

    return outfile, len(fast), np.sum(zdiff)

def check_catalogs(specprod_dir, fastspecdir, specprod, version, mp=1):
    
    # Read all the zpix catalogs in parallel.
    zcatfiles = sorted(glob(os.path.join(specprod_dir, 'zcatalog', 'zpix-*-*.fits')))
    mpargs = []
    for zcatfile in zcatfiles:
        mpargs.append([zcatfile, specprod, version])
    if mp > 1:
        with multiprocessing.Pool(mp) as P:
            out = P.map(_check_one_catalog, mpargs)
    else:
        out = [check_one_catalog(*mparg) for mparg in mpargs]
    out = list(zip(*out))
    fastfiles, nrows, nznews = list(out[0]), list(out[1]), list(out[2])

    # add the super-merged catalogs
    fastfile = os.path.join(fastspecdir, 'catalogs', 'fastspec-{}.fits'.format(specprod))
    fast = fitsio.read(fastfile, ext='METADATA', columns=['Z', 'Z_RR'])
    zdiff = fast['Z'] != fast['Z_RR']
    fastfile = os.path.basename(fastfile)
    #fastfile = fastfile.replace('fastspec-', '{fastspec,fastphot}-')
    fastfile = fastfile.replace('fastspec-', '{fastspec}-')

    fastfiles.append(fastfile)
    nrows.append(len(fast))
    nznews.append(np.sum(zdiff))

    headers = ['Catalog', 'Number of Objects', 'Number with Corrected Redshifts']
    widths = np.array([len(header) for header in headers])
    lines = []
    for fastfile, nrow, nznew in zip(fastfiles, nrows, nznews):
        oneline = []
        for ii, dd in enumerate([fastfile, nrow, nznew]):
            if type(dd) == int or type(dd) == np.int64:
                dd = '{:,d}'.format(dd)
            if len(dd) > widths[ii]:
                widths[ii] = len(dd)
            oneline.append(dd)
        lines.append(oneline)
    for ii, width in enumerate(widths):
        if ii == len(widths)-1:
            print(''.join(np.repeat('=', width)))
        else:
            print(''.join(np.repeat('=', width))+' ', end='')
    for ii, (width, dd) in enumerate(zip(widths, headers)):
        if ii == len(widths)-1:
            print(str.ljust(dd, width))
        else:
            print(str.ljust(dd, width)+' ', end='')
    for ii, width in enumerate(widths):
        if ii == len(widths)-1:
            print(''.join(np.repeat('=', width)))
        else:
            print(''.join(np.repeat('=', width))+' ', end='')            
    for line in lines:
        for ii, (width, dd) in enumerate(zip(widths, line)):
            if ii == len(widths)-1:
                print(str.ljust(dd, width))
            else:
                print(str.ljust(dd, width)+' ', end='')
    for ii, width in enumerate(widths):
        if ii == len(widths)-1:
            print(''.join(np.repeat('=', width)))
        else:
            print(''.join(np.repeat('=', width))+' ', end='')            

def fileinfo(filelist, sortbyrows=False):

    headers = ['File Name', 'File Size', 'Number of Targets']

    nrows, szs = [], []
    for onefile in filelist:
        szs.append(os.stat(onefile).st_size)
        nrows.append(fitsio.FITS(onefile)[1].get_nrows())
    szs = np.array(szs)
    nrows = np.array(nrows)

    if sortbyrows:
        srt = np.argsort(nrows)
    else:
        srt = np.arange(len(nrows))

    lines = []
    widths = np.array([len(header) for header in headers])
    for onefile, nrow, sz in zip(filelist[srt], nrows[srt], szs[srt]):
        if sz > 1024 and sz < 1024**2:
            sz /= 1024
            unit = 'KB'
            fmt = ''
        elif sz > 1024**2 and sz < 1024**3:
            sz /= 1024**2
            unit = 'MB'
            fmt = ''
        else:
            sz /= 1024**3
            unit = 'GB'

        sz = '{:.3g} {}'.format(sz, unit)

        basefile = os.path.basename(onefile)
        nrow = '{:,d}'.format(nrow)

        # get the widths
        oneline = []
        for ii, dd in enumerate([basefile, sz, nrow]):
            if len(dd) > widths[ii]:
                widths[ii] = len(dd)
            oneline.append(dd)

        lines.append(oneline)

    return widths, lines, headers

def build_table(widths, lines, headers):

    for ii, width in enumerate(widths):
        if ii == len(widths)-1:
            print(''.join(np.repeat('=', width)))
        else:
            print(''.join(np.repeat('=', width))+' ', end='')            
            
    for ii, (width, dd) in enumerate(zip(widths, headers)):
        if ii == len(widths)-1:
            print(str.ljust(dd, width))
        else:
            print(str.ljust(dd, width)+' ', end='')
    
    for ii, width in enumerate(widths):
        if ii == len(widths)-1:
            print(''.join(np.repeat('=', width)))
        else:
            print(''.join(np.repeat('=', width))+' ', end='')
            
    for line in lines:
        for ii, (width, dd) in enumerate(zip(widths, line)):
            if ii == len(widths)-1:
                print(str.ljust(dd, width))
            else:
                print(str.ljust(dd, width)+' ', end='')
                
    for ii, width in enumerate(widths):
        if ii == len(widths)-1:
            print(''.join(np.repeat('=', width)))
        else:
            print(''.join(np.repeat('=', width))+' ', end='')            

def build_table_withphot(specwidths, speclines, photwidths, photlines, specheaders, photheaders):

    headers = np.hstack((specheaders, photheaders))
    widths = np.hstack((specwidths, photwidths))
    lines = np.hstack((speclines, photlines))

    for ii, width in enumerate(widths):
        if ii == len(widths)-1:
            print(''.join(np.repeat('=', width)))
        else:
            print(''.join(np.repeat('=', width))+' ', end='')            
            
    for ii, (width, dd) in enumerate(zip(widths, headers)):
        if ii == len(widths)-1:
            print(str.ljust(dd, width))
        else:
            print(str.ljust(dd, width)+' ', end='')
    
    for ii, width in enumerate(widths):
        if ii == len(widths)-1:
            print(''.join(np.repeat('=', width)))
        else:
            print(''.join(np.repeat('=', width))+' ', end='')
            
    for line in lines:
        for ii, (width, dd) in enumerate(zip(widths, line)):
            if ii == len(widths)-1:
                print(str.ljust(dd, width))
            else:
                print(str.ljust(dd, width)+' ', end='')
                
    for ii, width in enumerate(widths):
        if ii == len(widths)-1:
            print(''.join(np.repeat('=', width)))
        else:
            print(''.join(np.repeat('=', width))+' ', end='')            

def _check_infinity_one(args):
    """Multiprocessing wrapper."""
    return check_infinity_one(*args) 

def check_infinity_one(fastfile, fastspecdir, specprod, specprod_dir, fastphot=False):

    if fastphot:
        script = 'fastphot'
        ext = 'FASTPHOT'
    else:
        script = 'fastspec'
        ext = 'FASTSPEC'

    log.info('Reading {}'.format(fastfile))
    fast = Table(fitsio.read(fastfile, ext=ext))#, rows=np.arange(5000)))
    #meta = Table(fitsio.read(fastfile, ext='METADATA'))#, rows=np.arange(5000)))

    fixfiles, healpixels = [], []
    for col in fast.colnames:
        if fast[col].dtype.type == np.str_:
            continue
        bad = np.where(np.logical_or(np.isinf(fast[col]), np.isnan(fast[col])))[0]
        if len(bad) > 0:
            #log.info('Found {} infinities in column {}'.format(len(bad), col))
            healpixels.append(fast['HEALPIX'][bad].tolist())
            #print(fast['SURVEY', 'PROGRAM', 'HEALPIX', 'TARGETID'][bad])
            for ibad in bad:
                fixfile = script+' '+os.path.join(specprod_dir, 'healpix', fast['SURVEY'][ibad], fast['PROGRAM'][ibad],
                                                  str(fast['HEALPIX'][ibad]//100), str(fast['HEALPIX'][ibad]),
                                                  'redrock-{}-{}-{}.fits'.format(fast['SURVEY'][ibad], fast['PROGRAM'][ibad],
                                                                                 fast['HEALPIX'][ibad]))+' --targetids '+str(fast['TARGETID'][ibad])+' -o {}.fits'.format(script)
                fixfiles.append(fixfile)
            
    if len(healpixels) > 0:
        healpixels = np.unique(np.hstack(healpixels))
        cmd = 'mpi-fastspecfit --overwrite --mp 128 --specprod {} --survey {} --program {} --healpix {}'.format(
            specprod, fast['SURVEY'][0], fast['PROGRAM'][0], ','.join([str(hpx) for hpx in healpixels]))
        log.info(cmd)
    else:
        log.info('No infinities found in specprod={} survey={} program={}!'.format(specprod, fast['SURVEY'][0], fast['PROGRAM'][0]))

    if len(fixfiles) > 0:
        fixfiles = np.unique(fixfiles)
        #print(fixfiles)

    #log.info('Working on METADATA HDU')
    #for col in meta.colnames:
    #    if meta[col].dtype.type == np.str_:
    #        continue
    #    bad = np.logical_or(np.isinf(meta[col]), np.isnan(meta[col]))
    #    if np.sum(bad) > 0:
    #        log.info('Found {} infinities in column {}'.format(np.sum(bad), col))
    #        print(meta['SURVEY', 'PROGRAM', 'TARGETID'][bad])
    #        print()
            
def check_infinity(fastspecdir, specprod_dir, specprod, mp=1, fastphot=False):

    if fastphot:
        fastfiles = glob(os.path.join(fastspecdir, 'catalogs', 'fastphot-{}-*-*.fits'.format(specprod)))
    else:
        fastfiles = glob(os.path.join(fastspecdir, 'catalogs', 'fastspec-{}-*-*.fits'.format(specprod)))
        
    mpargs = []
    for fastfile in fastfiles:
        mpargs.append([fastfile, fastspecdir, specprod, specprod_dir, fastphot])
        
    if mp > 1:
        with multiprocessing.Pool(mp) as P:
            P.map(_check_infinity_one, mpargs)
    else:
        [check_infinity_one(*mparg) for mparg in mpargs]

def main():

    p = argparse.ArgumentParser()
    p.add_argument('--specprod', type=str, required=True, help='output file prefix')
    p.add_argument('--version', type=str, required=True, help='production version')
    p.add_argument('--mp', type=int, default=1, help='number of multiprocessing cores')
    p.add_argument('--statistics', action='store_true', help='Do file statistics.')
    p.add_argument('--validate', action='store_true', help='Validate the files.')
    args = p.parse_args()

    fastspecdir = '/pscratch/sd/i/ioannis/fastspecfit/vac/data/iron'
    #fastspecdir = os.path.join(desi_root, 'spectro', 'fastspecfit', args.specprod, args.version)
    specprod_dir = os.path.join(desi_root, 'spectro', 'redux', args.specprod)

    if args.specprod == 'fuji':
        sortbyrows = False
    else:
        sortbyrows = True

    # Do statistics.
    if args.statistics:
        # by survey
        fastspecfiles = np.hstack((
            sorted(glob(os.path.join(fastspecdir, 'catalogs', f'fastspec-{args.specprod}-*-*.fits'))),
            glob(os.path.join(fastspecdir, 'catalogs', f'fastspec-{args.specprod}.fits')),
            glob(os.path.join(fastspecdir, 'catalogs', f'fastspec-{args.specprod}-special.fits')),
            glob(os.path.join(fastspecdir, 'catalogs', f'fastspec-{args.specprod}-sv.fits')),
            glob(os.path.join(fastspecdir, 'catalogs', f'fastspec-{args.specprod}-main.fits'))
            ))
        #fastphotfiles = np.hstack((sorted(glob(os.path.join(fastspecdir, 'catalogs', 'fastphot-{}-*.fits'.format(args.specprod)))),
        #                           os.path.join(fastspecdir, 'catalogs', 'fastphot-{}.fits'.format(args.specprod))))
        #fastspecfiles = np.array(sorted(glob(os.path.join(fastspecdir, 'catalogs', 'fastspec-{}-*.fits'.format(args.specprod)))))
        #fastphotfiles = np.array(sorted(glob(os.path.join(fastspecdir, 'catalogs', 'fastphot-{}-*.fits'.format(args.specprod)))))
        specwidths, speclines, specheaders = fileinfo(fastspecfiles, sortbyrows=sortbyrows)
        #photwidths, photlines, photheaders = fileinfo(fastphotfiles, sortbyrows=sortbyrows)
        #build_table_withphot(specwidths, speclines, photwidths, photlines, specheaders, photheaders)
        build_table(specwidths, speclines, specheaders)

    # Validate files.
    if args.validate:
        # check for infinity and other crap
        check_infinity(fastspecdir, specprod_dir, args.specprod, mp=args.mp)
        #check_infinity(fastspecdir, specprod_dir, args.specprod, mp=args.mp, fastphot=True)
        
        # verify that we have all the targets we expect and also summarize the
        # number of targets with corrected redshifts
        check_catalogs(specprod_dir, fastspecdir, args.specprod, args.version, mp=args.mp)

if __name__ == '__main__':
    main()
